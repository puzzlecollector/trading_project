{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import pickle\n",
    "import tqdm\n",
    "from konlpy.tag import Mecab\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from kss import split_sentences\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from transformers import * \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.functional as F \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold \n",
    "import random \n",
    "import time \n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "import gc\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "import seaborn as sns\n",
    "from kss import split_sentences\n",
    "import yfinance\n",
    "from pandas_datareader import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Scraped News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_news = pd.read_csv('005930_news_scraped.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>날짜</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기사제목</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021.03.25 16:02</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021.03.25 15:42</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021.03.25 11:52</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021.03.25 11:23</td>\n",
       "      <td>아시아경제</td>\n",
       "      <td>\"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021.03.25 11:07</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 날짜    언론사  \\\n",
       "0           0   2021.03.25 16:02   이데일리   \n",
       "1           1   2021.03.25 15:42   서울경제   \n",
       "2           2   2021.03.25 11:52  헤럴드경제   \n",
       "3           3   2021.03.25 11:23  아시아경제   \n",
       "4           4   2021.03.25 11:07   서울경제   \n",
       "\n",
       "                                         기사제목  \\\n",
       "0  온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...   \n",
       "1            삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발   \n",
       "2        1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공   \n",
       "3           \"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화   \n",
       "4   삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...   \n",
       "\n",
       "                                                  링크  \n",
       "0  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "1  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "2  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "3  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "4  https://finance.naver.com/item/news_read.nhn?a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_news['날짜'] = scraped_news['날짜'].apply(lambda x : x[:-6]) \n",
    "scraped_news['날짜'] = scraped_news['날짜'].apply(lambda x : x.strip(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>날짜</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기사제목</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>아시아경제</td>\n",
       "      <td>\"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          날짜    언론사                                        기사제목  \\\n",
       "0           0  2021.03.25   이데일리  온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...   \n",
       "1           1  2021.03.25   서울경제            삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발   \n",
       "2           2  2021.03.25  헤럴드경제        1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공   \n",
       "3           3  2021.03.25  아시아경제           \"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화   \n",
       "4           4  2021.03.25   서울경제   삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...   \n",
       "\n",
       "                                                  링크  \n",
       "0  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "1  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "2  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "3  https://finance.naver.com/item/news_read.nhn?a...  \n",
       "4  https://finance.naver.com/item/news_read.nhn?a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Samsung Chart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart_data = data.get_data_yahoo('035720.ks', '2016-01-01', '2021-03-25')\n",
    "#kakao_close = chart_data['Close'].values \n",
    "#plt.plot(kakao_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_data = data.get_data_yahoo('005930.ks', '2020-12-01', '2021-03-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_data['Date'] = chart_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_prices = chart_data['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_dates_raw = chart_data['Date'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_dates = []  \n",
    "for date in chart_dates_raw: \n",
    "    chart_dates.append(str(date).replace(\"T00:00:00.000000000\",\"\").replace(\"-\",\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price_dict = {} \n",
    "for i in range(len(chart_dates)): \n",
    "    close_price_dict[chart_dates[i]] = close_prices[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa4222c7978>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(close_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [] \n",
    "for i in range(0, len(close_prices)-1):  \n",
    "    \n",
    "    if close_prices[i] <= close_prices[i+1]:  \n",
    "        sentiments.append(1)\n",
    "    else: \n",
    "        sentiments.append(0)\n",
    "        \n",
    "sentiments = np.asarray(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label samsung financial news titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign labels by dates \n",
    "dates = scraped_news['날짜']  \n",
    "titles = scraped_news['기사제목'] \n",
    "\n",
    "table = {} \n",
    "for i in range(len(dates)): \n",
    "    table[dates[i]] = []  \n",
    "    \n",
    "for i in range(len(dates)):  \n",
    "    table[dates[i]].append(titles[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## table consists of the dates for when the news is released \n",
    "## if the close price next day is greater than the close price today, then we label the news today as 1 (+ve sentiment)\n",
    "## else we label it as 0 (+ve sentiment) \n",
    "\n",
    "labels = [] \n",
    "cur_date = '' \n",
    "for key in sorted(table.keys()):   \n",
    "    info = key.split('.')  \n",
    "    year = int(info[0]) \n",
    "    month = int(info[1]) \n",
    "    day = int(info[2])  \n",
    "    date = key.strip()    \n",
    "    if date in chart_dates: \n",
    "        cur_date = date  \n",
    "    while True: \n",
    "        if day >= 25 and month == 3: \n",
    "            break \n",
    "        \n",
    "        day += 1 \n",
    "        if month == 12 and day > 31:  \n",
    "            month = 1 \n",
    "            day = 1 \n",
    "            year = 2021\n",
    "        elif month == 1 and day > 31: \n",
    "            month = 2\n",
    "            day = 1 \n",
    "        elif month == 2 and day > 28: \n",
    "            month = 3 \n",
    "            day = 1  \n",
    "            \n",
    "            \n",
    "        if month < 10:  \n",
    "            str_month = '0' + str(month) \n",
    "        else: \n",
    "            str_month = str(month) \n",
    "            \n",
    "        if day < 10:  \n",
    "            str_day = '0' + str(day)  \n",
    "        else: \n",
    "            str_day = str(day)\n",
    "        \n",
    "        date = str(year) + '.' + str_month + '.' + str_day\n",
    "        \n",
    "        if date in chart_dates: \n",
    "            break \n",
    "        \n",
    "    \n",
    "    next_date = date \n",
    "    \n",
    "    if close_price_dict[cur_date] <= close_price_dict[next_date]: \n",
    "        labels.append(1) \n",
    "    else: \n",
    "        labels.append(0) \n",
    "        \n",
    "\n",
    "labels = np.asarray(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {} \n",
    "idx = 0 \n",
    "for key in sorted(table.keys()): \n",
    "    label_dict[key.strip()] = labels[idx] \n",
    "    idx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = [] \n",
    "news_dates = scraped_news['날짜'].values \n",
    "\n",
    "\n",
    "for date in news_dates: \n",
    "    df_labels.append(label_dict[date]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>날짜</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기사제목</th>\n",
       "      <th>링크</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>아시아경제</td>\n",
       "      <td>\"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          날짜    언론사                                        기사제목  \\\n",
       "0           0  2021.03.25   이데일리  온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...   \n",
       "1           1  2021.03.25   서울경제            삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발   \n",
       "2           2  2021.03.25  헤럴드경제        1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공   \n",
       "3           3  2021.03.25  아시아경제           \"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화   \n",
       "4           4  2021.03.25   서울경제   삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...   \n",
       "\n",
       "                                                  링크  sentiment  \n",
       "0  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "1  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "2  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "3  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "4  https://finance.naver.com/item/news_read.nhn?a...          1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_news['sentiment'] = df_labels \n",
    "\n",
    "scraped_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_news.to_csv('005930_news_scraped_labeled.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>날짜</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기사제목</th>\n",
       "      <th>링크</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>아시아경제</td>\n",
       "      <td>\"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021.03.25</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17802</th>\n",
       "      <td>17802</td>\n",
       "      <td>2020.12.01</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>삼성전자·SK하이닉스 덕분에…3분기 2%대 성장률 달성</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17803</th>\n",
       "      <td>17803</td>\n",
       "      <td>2020.12.01</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>애플·삼성 아니네?…'지속가능 100대 기업' 1위 어디길래</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17804</th>\n",
       "      <td>17804</td>\n",
       "      <td>2020.12.01</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>'7만 전자' 밀고가는 개미들…삼성전자 1.2조 쓸어담았다 [이슈+]</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805</th>\n",
       "      <td>17805</td>\n",
       "      <td>2020.12.01</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>애플 제친 샤오미…3분기 스마트폰 시장 1위는 ‘삼성’</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17806</th>\n",
       "      <td>17806</td>\n",
       "      <td>2020.12.01</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>개인·外人 사상 최초 2조戰, 삼성·네이버로 맞붙었다</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14478 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          날짜    언론사  \\\n",
       "0               0  2021.03.25   이데일리   \n",
       "1               1  2021.03.25   서울경제   \n",
       "2               2  2021.03.25  헤럴드경제   \n",
       "3               3  2021.03.25  아시아경제   \n",
       "4               4  2021.03.25   서울경제   \n",
       "...           ...         ...    ...   \n",
       "17802       17802  2020.12.01  머니투데이   \n",
       "17803       17803  2020.12.01   한국경제   \n",
       "17804       17804  2020.12.01   한국경제   \n",
       "17805       17805  2020.12.01  헤럴드경제   \n",
       "17806       17806  2020.12.01  헤럴드경제   \n",
       "\n",
       "                                             기사제목  \\\n",
       "0      온라인 마케팅 강화나서자 삼성 \"회원 40%↑\"…LG \"매출 비중 15...   \n",
       "1                삼성전자, 초고화질 영화 2편 1초에 전송하는 반도체 개발   \n",
       "2            1초에 UHD 영화 2편 내려 받는다...삼성 DDR5 개발 성공   \n",
       "3               \"차세대 시장 선도\" …삼성, 인텔과 고성능 D램 협력 강화   \n",
       "4       삼성, 세계 최초 혁신공정 적용한 차세대 DDR5 선보여···고성능·...   \n",
       "...                                           ...   \n",
       "17802              삼성전자·SK하이닉스 덕분에…3분기 2%대 성장률 달성   \n",
       "17803           애플·삼성 아니네?…'지속가능 100대 기업' 1위 어디길래   \n",
       "17804      '7만 전자' 밀고가는 개미들…삼성전자 1.2조 쓸어담았다 [이슈+]   \n",
       "17805              애플 제친 샤오미…3분기 스마트폰 시장 1위는 ‘삼성’   \n",
       "17806               개인·外人 사상 최초 2조戰, 삼성·네이버로 맞붙었다   \n",
       "\n",
       "                                                      링크  sentiment  \n",
       "0      https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "1      https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "2      https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "3      https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "4      https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "...                                                  ...        ...  \n",
       "17802  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "17803  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "17804  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "17805  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "17806  https://finance.naver.com/item/news_read.nhn?a...          1  \n",
       "\n",
       "[14478 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## positive sentiment \n",
    "scraped_news[scraped_news['sentiment']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>날짜</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기사제목</th>\n",
       "      <th>링크</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>2021.03.23</td>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>삼성 5G, 美 이어 日 1위 통신사 뚫었다</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>2021.03.23</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>삼성, 한미일 1위 이통사와 5G 공급계약…점유율 확대 ‘청신호’(종...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>2021.03.23</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>노조 입김 세진 삼성전자 임협…투명한 성과급 체계 요구</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>2021.03.23</td>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>삼성의 '5G 리더십' 초격차 전략 통했다</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>2021.03.23</td>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>삼성전자, 글로벌 통신사 NTT도코모에 5G 장비 공급</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>6604</td>\n",
       "      <td>2020.12.07</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>이재용 운명 가를 '삼성 준법위' 점검 결과 오늘 나온다</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>6605</td>\n",
       "      <td>2020.12.07</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>삼성전자, 환율 우려에도 새해 반도체 사업 개선 가속화-SK</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>6606</td>\n",
       "      <td>2020.12.07</td>\n",
       "      <td>아시아경제</td>\n",
       "      <td>삼성전자, 다음주 '글로벌 전략회의'…내년 사업계획 논의</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>6607</td>\n",
       "      <td>2020.12.07</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>[이번주 추천주]삼성전자·HSD엔진·SKT...수익 개선·배당 상향株 ...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>6609</td>\n",
       "      <td>2020.12.07</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>[이번주 추천주]삼성전자·HSD엔진·SKT...수익 개선·배당 상향株 ...</td>\n",
       "      <td>https://finance.naver.com/item/news_read.nhn?a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3329 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0          날짜     언론사  \\\n",
       "68            68  2021.03.23  파이낸셜뉴스   \n",
       "69            69  2021.03.23    이데일리   \n",
       "70            70  2021.03.23    이데일리   \n",
       "71            71  2021.03.23  파이낸셜뉴스   \n",
       "72            72  2021.03.23  파이낸셜뉴스   \n",
       "...          ...         ...     ...   \n",
       "6604        6604  2020.12.07    한국경제   \n",
       "6605        6605  2020.12.07    이데일리   \n",
       "6606        6606  2020.12.07   아시아경제   \n",
       "6607        6607  2020.12.07    서울경제   \n",
       "6609        6609  2020.12.07    서울경제   \n",
       "\n",
       "                                            기사제목  \\\n",
       "68                      삼성 5G, 美 이어 日 1위 통신사 뚫었다   \n",
       "69     삼성, 한미일 1위 이통사와 5G 공급계약…점유율 확대 ‘청신호’(종...   \n",
       "70                노조 입김 세진 삼성전자 임협…투명한 성과급 체계 요구   \n",
       "71                       삼성의 '5G 리더십' 초격차 전략 통했다   \n",
       "72                삼성전자, 글로벌 통신사 NTT도코모에 5G 장비 공급   \n",
       "...                                          ...   \n",
       "6604             이재용 운명 가를 '삼성 준법위' 점검 결과 오늘 나온다   \n",
       "6605           삼성전자, 환율 우려에도 새해 반도체 사업 개선 가속화-SK   \n",
       "6606             삼성전자, 다음주 '글로벌 전략회의'…내년 사업계획 논의   \n",
       "6607  [이번주 추천주]삼성전자·HSD엔진·SKT...수익 개선·배당 상향株 ...   \n",
       "6609  [이번주 추천주]삼성전자·HSD엔진·SKT...수익 개선·배당 상향株 ...   \n",
       "\n",
       "                                                     링크  sentiment  \n",
       "68    https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "69    https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "70    https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "71    https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "72    https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "...                                                 ...        ...  \n",
       "6604  https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "6605  https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "6606  https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "6607  https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "6609  https://finance.naver.com/item/news_read.nhn?a...          0  \n",
       "\n",
       "[3329 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_news[scraped_news['sentiment']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = scraped_news['기사제목'].values \n",
    "sentiment_data = scraped_news['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define utility functions \n",
    "def clean_text(s):  \n",
    "    FILTERS = \"([~.,!?\\\"':;(])\" \n",
    "    CHANGE_FILTER = re.compile(FILTERS) \n",
    "    return re.sub(CHANGE_FILTER, \"\", s)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(vocab_file='bert_kor_mecab/vocab.txt', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN): \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent, \n",
    "        add_special_tokens = True, \n",
    "        max_length = MAX_LEN, \n",
    "        pad_to_max_length = True,\n",
    "        truncation = True, \n",
    "        return_attention_mask = True \n",
    "    )\n",
    "    input_id = encoded_dict['input_ids'] \n",
    "    attention_mask = encoded_dict['attention_mask'] \n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17807 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|██████████| 17807/17807 [00:04<00:00, 4071.94it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = [] \n",
    "attention_masks = []\n",
    "token_type_ids = [] \n",
    "\n",
    "for i in tqdm(range(len(titles)), position = 0, leave = True):  \n",
    "    title = clean_text(titles[i].replace('\\n','')) \n",
    "    input_id, attention_mask, token_type_id  = bert_tokenizer(title, 100) \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask) \n",
    "    token_type_ids.append(token_type_id)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, sentiment_data, random_state=42, test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=42, \n",
    "                                                       test_size=0.1) \n",
    "\n",
    "\n",
    "train_token_type_ids, validation_token_type_ids, _, _ = train_test_split(token_type_ids, input_ids, random_state = 42, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "train_token_type_ids = torch.tensor(train_token_type_ids)\n",
    "\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "validation_token_type_ids = torch.tensor(validation_token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16026, 100]), torch.Size([1781, 100]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape, validation_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_token_type_ids, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_token_type_ids, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tf_checkpoint_to_pytorch(tf_checkpoint_path, bert_config_file, pytorch_dump_path):\n",
    "    # Initialise PyTorch model\n",
    "    config = BertConfig.from_json_file(bert_config_file)\n",
    "    print(\"Building PyTorch model from configuration: {}\".format(str(config)))\n",
    "    model = BertForPreTraining(config)\n",
    "    # Load weights from tf checkpoint\n",
    "    load_tf_weights_in_bert(model, config, tf_checkpoint_path)   \n",
    "    print(\"Finished process\")\n",
    "    return model \n",
    "    # Save pytorch-model\n",
    "    weights_file = pytorch_dump_path + 'bert_model.bin'\n",
    "    print(\"Save PyTorch model to {}\".format(weights_file))\n",
    "    torch.save(model.state_dict(), pytorch_dump_path)\n",
    "    config.save_pretrained(pytorch_dump_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building PyTorch model from configuration: BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 112089\n",
      "}\n",
      "\n",
      "Finished process\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to the TensorFlow checkpoint path.\n",
    "    tf_checkpoint_path = \"bert_kor_mecab/bert_model.ckpt\" #\"D:/Heklis/bin/chinese_L-12_H-768_A-12/bert_model.ckpt\"\n",
    "    # The config json file corresponding to the pre-trained BERT model. \n",
    "    # This specifies the model architecture.\n",
    "    bert_config_file = \"bert_kor_mecab/bert_config.json\"\n",
    "    # Path to the output PyTorch model.\n",
    "    pytorch_dump_path = \"\"\n",
    "    model = convert_tf_checkpoint_to_pytorch(tf_checkpoint_path,\n",
    "                                     bert_config_file,\n",
    "                                     pytorch_dump_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(112089, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=112089, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [] \n",
    "def compute_accuracy(model, dataloader, device):\n",
    "    tqdm()\n",
    "    model.eval()\n",
    "    correct_preds, num_samples = 0,0\n",
    "    predictions = [] \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader, position = 0, leave = True)):\n",
    "            b_input_ids, b_input_masks, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch) \n",
    "            _, yhat = model(b_input_ids,  b_input_masks,  b_token_type_ids) \n",
    "            prediction = (torch.sigmoid(yhat[:,1]) > 0.5).long() \n",
    "            predictions.append(torch.sigmoid(yhat[:,1]))  \n",
    "            num_samples += b_labels.size(0)\n",
    "            correct_preds += (prediction==b_labels.long()).sum()\n",
    "            del b_input_ids, b_input_masks, b_token_type_ids, b_labels #memory\n",
    "        torch.cuda.empty_cache() #memory\n",
    "        gc.collect() # memory \n",
    "        return correct_preds.float()/num_samples*100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed): \n",
    "    elapsed_rounded = int(round(elapsed)) \n",
    "    return str(datetime.timedelta(seconds = elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1 / 10 =====\n",
      "Training ...\n",
      "Epoch: 001/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 1.9486 | Elapsed 0:00:01\n",
      "Epoch: 001/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.4369 | Elapsed 0:00:13\n",
      "Epoch: 001/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.3316 | Elapsed 0:00:25\n",
      "Epoch: 001/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.2837 | Elapsed 0:00:37\n",
      "Epoch: 001/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.2640 | Elapsed 0:00:49\n",
      "Epoch: 001/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.2623 | Elapsed 0:01:01\n",
      "Epoch: 001/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.2197 | Elapsed 0:01:25\n",
      "Epoch: 001/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.2236 | Elapsed 0:01:38\n",
      "Epoch: 001/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.2720 | Elapsed 0:02:10\n",
      "Epoch: 001/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.2390 | Elapsed 0:02:36\n",
      "Epoch: 001/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.2269 | Elapsed 0:03:17\n",
      "Epoch: 001/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.2168 | Elapsed 0:03:29\n",
      "Epoch: 001/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.2374 | Elapsed 0:04:39\n",
      "Epoch: 001/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.2275 | Elapsed 0:05:19\n",
      "Epoch: 001/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.2109 | Elapsed 0:05:31\n",
      "Epoch: 001/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.1966 | Elapsed 0:05:43\n",
      "Epoch: 001/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.1739 | Elapsed 0:05:58\n",
      "Epoch: 001/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.1920 | Elapsed 0:06:53\n",
      "Epoch: 001/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.1968 | Elapsed 0:07:13\n",
      "Epoch: 001/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.1667 | Elapsed 0:07:24\n",
      "Epoch: 001/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.1931 | Elapsed 0:07:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/501 [00:00<00:46, 10.61it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 94.90%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.17735396508526588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:04, 11.70it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 92.47614288330078\n",
      "\n",
      "===== Epoch 2 / 10 =====\n",
      "Training ...\n",
      "Epoch: 002/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.2142 | Elapsed 0:00:00\n",
      "Epoch: 002/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.1140 | Elapsed 0:00:15\n",
      "Epoch: 002/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.1328 | Elapsed 0:00:33\n",
      "Epoch: 002/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.1165 | Elapsed 0:01:59\n",
      "Epoch: 002/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.1312 | Elapsed 0:02:21\n",
      "Epoch: 002/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.1032 | Elapsed 0:02:50\n",
      "Epoch: 002/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0899 | Elapsed 0:03:02\n",
      "Epoch: 002/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.1013 | Elapsed 0:03:14\n",
      "Epoch: 002/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.1192 | Elapsed 0:03:34\n",
      "Epoch: 002/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0998 | Elapsed 0:04:15\n",
      "Epoch: 002/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.1313 | Elapsed 0:04:39\n",
      "Epoch: 002/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0967 | Elapsed 0:05:08\n",
      "Epoch: 002/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0858 | Elapsed 0:05:20\n",
      "Epoch: 002/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 0:05:42\n",
      "Epoch: 002/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 0:06:33\n",
      "Epoch: 002/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.1046 | Elapsed 0:08:36\n",
      "Epoch: 002/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.1068 | Elapsed 0:08:51\n",
      "Epoch: 002/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 0:09:03\n",
      "Epoch: 002/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 0:09:15\n",
      "Epoch: 002/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.1077 | Elapsed 0:09:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/501 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0766 | Elapsed 0:09:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/501 [00:00<00:46, 10.58it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 98.95%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.1570329662478928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:04, 11.74it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 94.49747467041016\n",
      "\n",
      "===== Epoch 3 / 10 =====\n",
      "Training ...\n",
      "Epoch: 003/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0638 | Elapsed 0:00:03\n",
      "Epoch: 003/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0347 | Elapsed 0:00:29\n",
      "Epoch: 003/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0719 | Elapsed 0:00:40\n",
      "Epoch: 003/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0592 | Elapsed 0:00:52\n",
      "Epoch: 003/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0778 | Elapsed 0:01:04\n",
      "Epoch: 003/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0621 | Elapsed 0:01:16\n",
      "Epoch: 003/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0450 | Elapsed 0:01:37\n",
      "Epoch: 003/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0538 | Elapsed 0:02:01\n",
      "Epoch: 003/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0772 | Elapsed 0:03:03\n",
      "Epoch: 003/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0624 | Elapsed 0:03:15\n",
      "Epoch: 003/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 0:03:48\n",
      "Epoch: 003/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0275 | Elapsed 0:04:03\n",
      "Epoch: 003/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0458 | Elapsed 0:04:15\n",
      "Epoch: 003/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0655 | Elapsed 0:04:28\n",
      "Epoch: 003/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0677 | Elapsed 0:05:08\n",
      "Epoch: 003/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0315 | Elapsed 0:05:33\n",
      "Epoch: 003/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0591 | Elapsed 0:05:45\n",
      "Epoch: 003/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0496 | Elapsed 0:06:00\n",
      "Epoch: 003/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0424 | Elapsed 0:06:37\n",
      "Epoch: 003/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0244 | Elapsed 0:07:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/501 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0879 | Elapsed 0:07:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]/501 [00:01<01:05,  7.51it/s]\n",
      "100%|██████████| 501/501 [00:51<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.57%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:03, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.19184104197276092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:05<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 95.50814819335938\n",
      "\n",
      "===== Epoch 4 / 10 =====\n",
      "Training ...\n",
      "Epoch: 004/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0052 | Elapsed 0:00:06\n",
      "Epoch: 004/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0273 | Elapsed 0:00:48\n",
      "Epoch: 004/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0280 | Elapsed 0:01:00\n",
      "Epoch: 004/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0431 | Elapsed 0:01:11\n",
      "Epoch: 004/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0209 | Elapsed 0:01:23\n",
      "Epoch: 004/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0309 | Elapsed 0:01:36\n",
      "Epoch: 004/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0138 | Elapsed 0:01:47\n",
      "Epoch: 004/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0439 | Elapsed 0:01:59\n",
      "Epoch: 004/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0421 | Elapsed 0:02:10\n",
      "Epoch: 004/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0214 | Elapsed 0:02:22\n",
      "Epoch: 004/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0231 | Elapsed 0:03:38\n",
      "Epoch: 004/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0313 | Elapsed 0:03:51\n",
      "Epoch: 004/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0174 | Elapsed 0:04:04\n",
      "Epoch: 004/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0348 | Elapsed 0:04:17\n",
      "Epoch: 004/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0331 | Elapsed 0:04:29\n",
      "Epoch: 004/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0318 | Elapsed 0:05:54\n",
      "Epoch: 004/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0331 | Elapsed 0:06:26\n",
      "Epoch: 004/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0303 | Elapsed 0:06:38\n",
      "Epoch: 004/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0189 | Elapsed 0:06:55\n",
      "Epoch: 004/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0264 | Elapsed 0:07:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/501 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0177 | Elapsed 0:07:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/501 [00:00<00:46, 10.58it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.81%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 17.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.2153183316238158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:04, 11.89it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 95.95733642578125\n",
      "\n",
      "===== Epoch 5 / 10 =====\n",
      "Training ...\n",
      "Epoch: 005/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0045 | Elapsed 0:00:02\n",
      "Epoch: 005/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0110 | Elapsed 0:00:46\n",
      "Epoch: 005/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0018 | Elapsed 0:01:02\n",
      "Epoch: 005/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0101 | Elapsed 0:01:14\n",
      "Epoch: 005/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0035 | Elapsed 0:01:43\n",
      "Epoch: 005/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0119 | Elapsed 0:02:07\n",
      "Epoch: 005/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0163 | Elapsed 0:03:20\n",
      "Epoch: 005/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0129 | Elapsed 0:03:37\n",
      "Epoch: 005/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0047 | Elapsed 0:04:18\n",
      "Epoch: 005/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0226 | Elapsed 0:04:30\n",
      "Epoch: 005/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0151 | Elapsed 0:04:42\n",
      "Epoch: 005/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0318 | Elapsed 0:04:55\n",
      "Epoch: 005/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0391 | Elapsed 0:05:09\n",
      "Epoch: 005/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0271 | Elapsed 0:06:20\n",
      "Epoch: 005/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0139 | Elapsed 0:06:36\n",
      "Epoch: 005/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0131 | Elapsed 0:06:49\n",
      "Epoch: 005/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0264 | Elapsed 0:07:02\n",
      "Epoch: 005/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0106 | Elapsed 0:07:15\n",
      "Epoch: 005/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0293 | Elapsed 0:08:13\n",
      "Epoch: 005/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0109 | Elapsed 0:09:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/501 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0119 | Elapsed 0:09:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/501 [00:00<00:46, 10.52it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.79%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.2153758302436992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:04, 11.78it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 95.95733642578125\n",
      "\n",
      "===== Epoch 6 / 10 =====\n",
      "Training ...\n",
      "Epoch: 006/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0670 | Elapsed 0:00:02\n",
      "Epoch: 006/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0149 | Elapsed 0:00:13\n",
      "Epoch: 006/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0108 | Elapsed 0:00:25\n",
      "Epoch: 006/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0117 | Elapsed 0:00:39\n",
      "Epoch: 006/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0108 | Elapsed 0:00:53\n",
      "Epoch: 006/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0105 | Elapsed 0:01:05\n",
      "Epoch: 006/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0079 | Elapsed 0:01:17\n",
      "Epoch: 006/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0130 | Elapsed 0:01:30\n",
      "Epoch: 006/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0097 | Elapsed 0:01:47\n",
      "Epoch: 006/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0122 | Elapsed 0:03:05\n",
      "Epoch: 006/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0009 | Elapsed 0:03:19\n",
      "Epoch: 006/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0088 | Elapsed 0:03:31\n",
      "Epoch: 006/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0111 | Elapsed 0:04:31\n",
      "Epoch: 006/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0051 | Elapsed 0:05:57\n",
      "Epoch: 006/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0122 | Elapsed 0:06:10\n",
      "Epoch: 006/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0218 | Elapsed 0:06:22\n",
      "Epoch: 006/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0048 | Elapsed 0:06:33\n",
      "Epoch: 006/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0164 | Elapsed 0:06:45\n",
      "Epoch: 006/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0166 | Elapsed 0:06:57\n",
      "Epoch: 006/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0023 | Elapsed 0:07:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/501 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0140 | Elapsed 0:07:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]0/501 [00:00<00:47, 10.33it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.87%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.26164797986400246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:04, 11.91it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 95.50814819335938\n",
      "\n",
      "===== Epoch 7 / 10 =====\n",
      "Training ...\n",
      "Epoch: 007/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0002 | Elapsed 0:00:00\n",
      "Epoch: 007/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0145 | Elapsed 0:00:13\n",
      "Epoch: 007/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0079 | Elapsed 0:00:25\n",
      "Epoch: 007/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0028 | Elapsed 0:00:38\n",
      "Epoch: 007/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0093 | Elapsed 0:00:50\n",
      "Epoch: 007/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0067 | Elapsed 0:01:02\n",
      "Epoch: 007/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0062 | Elapsed 0:02:06\n",
      "Epoch: 007/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0005 | Elapsed 0:02:18\n",
      "Epoch: 007/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0084 | Elapsed 0:02:39\n",
      "Epoch: 007/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0123 | Elapsed 0:02:57\n",
      "Epoch: 007/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0031 | Elapsed 0:03:14\n",
      "Epoch: 007/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0104 | Elapsed 0:03:27\n",
      "Epoch: 007/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0017 | Elapsed 0:03:39\n",
      "Epoch: 007/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0098 | Elapsed 0:03:51\n",
      "Epoch: 007/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0157 | Elapsed 0:04:03\n",
      "Epoch: 007/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0098 | Elapsed 0:04:15\n",
      "Epoch: 007/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0099 | Elapsed 0:04:27\n",
      "Epoch: 007/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0053 | Elapsed 0:04:48\n",
      "Epoch: 007/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0020 | Elapsed 0:05:20\n",
      "Epoch: 007/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0123 | Elapsed 0:05:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0067 | Elapsed 0:06:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]0/501 [00:00<00:47, 10.31it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.89%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.2431032908542485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:04, 11.89it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 95.95733642578125\n",
      "\n",
      "===== Epoch 8 / 10 =====\n",
      "Training ...\n",
      "Epoch: 008/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0002 | Elapsed 0:00:17\n",
      "Epoch: 008/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0020 | Elapsed 0:00:50\n",
      "Epoch: 008/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0141 | Elapsed 0:01:10\n",
      "Epoch: 008/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0003 | Elapsed 0:01:35\n",
      "Epoch: 008/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0070 | Elapsed 0:01:53\n",
      "Epoch: 008/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0093 | Elapsed 0:03:11\n",
      "Epoch: 008/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0035 | Elapsed 0:03:41\n",
      "Epoch: 008/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0018 | Elapsed 0:04:17\n",
      "Epoch: 008/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0086 | Elapsed 0:04:50\n",
      "Epoch: 008/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0181 | Elapsed 0:05:01\n",
      "Epoch: 008/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0019 | Elapsed 0:05:27\n",
      "Epoch: 008/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0112 | Elapsed 0:06:45\n",
      "Epoch: 008/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0003 | Elapsed 0:06:57\n",
      "Epoch: 008/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0101 | Elapsed 0:07:09\n",
      "Epoch: 008/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0044 | Elapsed 0:07:24\n",
      "Epoch: 008/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0045 | Elapsed 0:08:01\n",
      "Epoch: 008/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0003 | Elapsed 0:08:12\n",
      "Epoch: 008/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0034 | Elapsed 0:08:25\n",
      "Epoch: 008/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0062 | Elapsed 0:08:37\n",
      "Epoch: 008/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0026 | Elapsed 0:09:13\n",
      "Epoch: 008/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0131 | Elapsed 0:10:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]0/501 [00:00<00:47, 10.37it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.90%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.2489373423118845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:04, 11.84it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 96.01348114013672\n",
      "\n",
      "===== Epoch 9 / 10 =====\n",
      "Training ...\n",
      "Epoch: 009/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0002 | Elapsed 0:00:03\n",
      "Epoch: 009/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0035 | Elapsed 0:01:35\n",
      "Epoch: 009/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0037 | Elapsed 0:01:57\n",
      "Epoch: 009/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0040 | Elapsed 0:02:23\n",
      "Epoch: 009/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0018 | Elapsed 0:02:35\n",
      "Epoch: 009/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0020 | Elapsed 0:02:56\n",
      "Epoch: 009/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0057 | Elapsed 0:03:09\n",
      "Epoch: 009/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0014 | Elapsed 0:03:40\n",
      "Epoch: 009/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0012 | Elapsed 0:04:14\n",
      "Epoch: 009/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0018 | Elapsed 0:04:39\n",
      "Epoch: 009/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0033 | Elapsed 0:04:57\n",
      "Epoch: 009/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0018 | Elapsed 0:05:13\n",
      "Epoch: 009/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0010 | Elapsed 0:05:34\n",
      "Epoch: 009/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0004 | Elapsed 0:05:46\n",
      "Epoch: 009/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0069 | Elapsed 0:05:58\n",
      "Epoch: 009/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0096 | Elapsed 0:07:30\n",
      "Epoch: 009/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0001 | Elapsed 0:08:06\n",
      "Epoch: 009/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0072 | Elapsed 0:08:22\n",
      "Epoch: 009/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0020 | Elapsed 0:08:34\n",
      "Epoch: 009/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0042 | Elapsed 0:08:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/501 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0007 | Elapsed 0:09:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]/501 [00:01<01:05,  7.47it/s]\n",
      "100%|██████████| 501/501 [00:51<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.91%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2/56 [00:00<00:03, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.24818297242226045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 56/56 [00:05<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 96.06962585449219\n",
      "\n",
      "===== Epoch 10 / 10 =====\n",
      "Training ...\n",
      "Epoch: 010/010 | Batch 001/501 | Average Loss in last 1 iteration(s): 0.0701 | Elapsed 0:00:04\n",
      "Epoch: 010/010 | Batch 026/501 | Average Loss in last 25 iteration(s): 0.0004 | Elapsed 0:00:25\n",
      "Epoch: 010/010 | Batch 051/501 | Average Loss in last 25 iteration(s): 0.0023 | Elapsed 0:00:50\n",
      "Epoch: 010/010 | Batch 076/501 | Average Loss in last 25 iteration(s): 0.0009 | Elapsed 0:01:35\n",
      "Epoch: 010/010 | Batch 101/501 | Average Loss in last 25 iteration(s): 0.0013 | Elapsed 0:03:12\n",
      "Epoch: 010/010 | Batch 126/501 | Average Loss in last 25 iteration(s): 0.0005 | Elapsed 0:03:42\n",
      "Epoch: 010/010 | Batch 151/501 | Average Loss in last 25 iteration(s): 0.0023 | Elapsed 0:04:20\n",
      "Epoch: 010/010 | Batch 176/501 | Average Loss in last 25 iteration(s): 0.0064 | Elapsed 0:04:36\n",
      "Epoch: 010/010 | Batch 201/501 | Average Loss in last 25 iteration(s): 0.0085 | Elapsed 0:04:47\n",
      "Epoch: 010/010 | Batch 226/501 | Average Loss in last 25 iteration(s): 0.0044 | Elapsed 0:04:59\n",
      "Epoch: 010/010 | Batch 251/501 | Average Loss in last 25 iteration(s): 0.0014 | Elapsed 0:05:12\n",
      "Epoch: 010/010 | Batch 276/501 | Average Loss in last 25 iteration(s): 0.0007 | Elapsed 0:05:24\n",
      "Epoch: 010/010 | Batch 301/501 | Average Loss in last 25 iteration(s): 0.0071 | Elapsed 0:06:15\n",
      "Epoch: 010/010 | Batch 326/501 | Average Loss in last 25 iteration(s): 0.0042 | Elapsed 0:06:54\n",
      "Epoch: 010/010 | Batch 351/501 | Average Loss in last 25 iteration(s): 0.0030 | Elapsed 0:07:05\n",
      "Epoch: 010/010 | Batch 376/501 | Average Loss in last 25 iteration(s): 0.0062 | Elapsed 0:07:17\n",
      "Epoch: 010/010 | Batch 401/501 | Average Loss in last 25 iteration(s): 0.0005 | Elapsed 0:07:29\n",
      "Epoch: 010/010 | Batch 426/501 | Average Loss in last 25 iteration(s): 0.0021 | Elapsed 0:07:42\n",
      "Epoch: 010/010 | Batch 451/501 | Average Loss in last 25 iteration(s): 0.0005 | Elapsed 0:09:17\n",
      "Epoch: 010/010 | Batch 476/501 | Average Loss in last 25 iteration(s): 0.0030 | Elapsed 0:09:35\n",
      "Epoch: 010/010 | Batch 501/501 | Average Loss in last 25 iteration(s): 0.0012 | Elapsed 0:10:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/501 [00:00<00:46, 10.61it/s]\n",
      "100%|██████████| 501/501 [00:50<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 99.93%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/56 [00:00<00:03, 16.77it/s]\n",
      "  7%|▋         | 4/56 [00:10<00:04, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.2477805108753403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:15<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 96.01348114013672\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility \n",
    "seed_val = 8888 \n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val) \n",
    "\n",
    "# binary cross entropy with sigmoid \n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8) \n",
    "epochs = 10 \n",
    "total_steps = len(train_dataloader) * epochs \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps) \n",
    "\n",
    "losses = [] \n",
    "val_losses = [] \n",
    "#model.zero_grad() \n",
    "\n",
    "for epoch_i in range(0, epochs): \n",
    "    print(\"\")\n",
    "    print(\"===== Epoch {:} / {:} =====\".format(epoch_i + 1, epochs)) \n",
    "    print(\"Training ...\") \n",
    "    t0 = time.time()\n",
    "    running_loss = 0 \n",
    "    train_accuracy = 0\n",
    "    iteration = 0 \n",
    "    model.train() \n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):       \n",
    "        iteration += 1 \n",
    "        batch = tuple(t.to(device) for t in batch) \n",
    "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch \n",
    "        _, yhat = model(b_input_ids,  b_input_masks,  b_token_type_ids)  \n",
    "    \n",
    "        \n",
    "        loss = criterion(yhat[:,1], b_labels.float())  \n",
    "        \n",
    "        running_loss += float(loss.item())\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  \n",
    "        model.zero_grad()\n",
    "\n",
    "        del b_input_ids, b_input_masks, b_token_type_ids, b_labels #memory\n",
    "        \n",
    "        if not step%25:\n",
    "            print(f'Epoch: {epoch_i+1:03d}/{epochs:03d} | '\n",
    "                  f'Batch {step+1:03d}/{len(train_dataloader):03d} | '\n",
    "                  f'Average Loss in last {iteration} iteration(s): {(running_loss/iteration):.4f} | '\n",
    "                  f'Elapsed {format_time(time.time()-t0)}')\n",
    "            running_loss = 0.0\n",
    "            iteration = 0\n",
    "        torch.cuda.empty_cache() #memory\n",
    "        gc.collect() #memory\n",
    "        losses.append(float(loss.item()))  \n",
    "        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print(f'\\nTraining Accuracy: ' f'{compute_accuracy(model, train_dataloader, device):.2f}%')\n",
    "        \n",
    "        \n",
    "    print(\"Calculating validation metrics...\")\n",
    "    model.eval() \n",
    "    eval_loss = 0\n",
    "    eval_accuracy = 0\n",
    "    for batch in validation_dataloader: \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch \n",
    "        with torch.no_grad(): \n",
    "            _, yhat = model(b_input_ids, b_input_masks, b_token_type_ids) \n",
    "        \n",
    "        \n",
    "        loss = criterion(yhat[:,1], b_labels.float())\n",
    "        eval_loss += float(loss.item())  \n",
    "        del b_input_ids, b_input_masks, b_token_type_ids, b_labels # memory \n",
    "        val_losses.append(float(loss.item())) \n",
    "        \n",
    "    avg_val_loss = eval_loss / len(validation_dataloader) \n",
    "    # avg_val_accuracy = eval_accuracy / len(val_dataloader)   \n",
    "    \n",
    "    print(\"Average validation loss = {}\".format(avg_val_loss)) \n",
    "    print(\"Average validation accuracy = {}\".format(compute_accuracy(model, validation_dataloader, device)))  \n",
    "    \n",
    "    # saving model \n",
    "    torch.save(model.state_dict(), 'BERT_samsung_sentiment_' + str(epoch_i + 1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
